{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323766a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bd00bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Danny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "C:\\Users\\Danny\\anaconda3\\lib\\site-packages\\gensim\\matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Danny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Danny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Danny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Danny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import count\n",
    "from matplotlib.pyplot import polar\n",
    "import pandas as pd\n",
    "from email import header\n",
    "import re\n",
    "import nltk\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('omw-1.4')\n",
    "import gensim\n",
    "nltk.download(\"vader_lexicon\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "newStpWord = [',','–','!','\"','#','$','%','&',')','*','+','&',\"i'm\",\"I'm\",\"I've\",'you','me',\"i've\",'0','1','2','3','4','5','6','7','8','9','?','and','or','however','course.','course',\"much\",'more']\n",
    "nltk_stopwords.extend(newStpWord)\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim.corpora as corpora\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "#import pyLDAvis.gensim\n",
    "from string import punctuation\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf1ec5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: DeprecationWarning: invalid escape sequence \\p\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\p\n",
      "C:\\Users\\Danny\\AppData\\Local\\Temp\\ipykernel_16424\\3137898726.py:5: DeprecationWarning: invalid escape sequence \\p\n",
      "  path = 'E:\\python\\Sentiment&LDA\\Import_Data_complete_final_sentenized.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96845\n",
      "pos rev:\n",
      "73313\n",
      "neg rev:\n",
      "4873\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "pos = []\n",
    "neg = []\n",
    "sent_ls = [] #存欲分類正負情感之字串\n",
    "path = 'E:\\python\\Sentiment&LDA\\Import_Data_complete_final_sentenized.csv'\n",
    "f = open(path, 'r',encoding=\"utf-8\")\n",
    "rows = csv.reader(f, delimiter=',')\n",
    "for row in rows:\n",
    "    sent_ls.append(row[2])\n",
    "\n",
    "res = [idx for idx in sent_ls if not re.findall(\"[^\\u0000-\\u05C0\\u2100-\\u214F]+\", idx)] #res = 20114筆\n",
    "clean_data = []\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemma(text):\n",
    "    \n",
    "    lst_text = nltk.word_tokenize(text)\n",
    "    lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    lemmatized_output = ' '.join([lem.lemmatize(w) for w in lst_text])\n",
    "    #lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "    \n",
    "    #if lst_text == text:\n",
    "    #    lst_text = [lem.lemmatize(word, 'n') for word in text]\n",
    "    #text = \" \".join(lst_text)\n",
    "    return lemmatized_output\n",
    "\n",
    "for i in res:\n",
    "    p = re.sub(r'[.,\"\\'-?:!;]', '', i)\n",
    "    txt_lemma = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(p)]\n",
    "    text = \" \".join(txt_lemma)\n",
    "    clean_data.append(text) \n",
    "sent_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "test = pd.DataFrame(clean_data)\n",
    "test.columns = [\"reviews\"]\n",
    "\n",
    "def format_output(output_dict):\n",
    "    polarity = \"neutral\"\n",
    "    if (output_dict['compound']>=0.05):\n",
    "        polarity = \"positive\"\n",
    "    elif(output_dict['compound']<=-0.05):\n",
    "        polarity = \"negative\"\n",
    "    return polarity\n",
    "\n",
    "def sentiment_calc(text):\n",
    "     try:\n",
    "         return sent_analyzer.polarity_scores(text)\n",
    "     except:\n",
    "         return None\n",
    "test['sentiment_polarity'] = test['reviews'].apply(sentiment_calc)\n",
    "test['pos_or_neg'] = test['sentiment_polarity'].apply(format_output)\n",
    "\n",
    "for row in range (len(clean_data)):\n",
    "    if test.loc[row][2]==\"positive\":\n",
    "        pos.append(test.loc[row][0])       #positive review array list\n",
    "    elif test.loc[row][2]==\"negative\":\n",
    "        neg.append(test.loc[row][0])       #negative review array list\n",
    "\n",
    "newStpWord_2 = ['game','Game', \"i'm\",\"I'm\",\"I've\",       #extend sentiment stopwords fo pos and neg\n",
    "\"i've\",'0','1','2','3','4','5','6','7','8','9','?','sorry','course.','dr','chuck','get','excellent','make','let','take','el','la','cod','quite','however','other','others','arduino','give','be','iam','im','ive','one','thank','yes','no','not','do','can','this','it','to','the','course','best','good','bad','great',\"'great\",\",good\",\",great\",\"'amazing\",'``',\"`\",'nice','java',\n",
    "'like','love','lot','little','go','really','well','python','easy','me','you','programming','course,',\"coursera\",'could',\"'good\",\"''\",\"'\",'would','many','much','also','awesome','excellent']\n",
    "\n",
    "\n",
    "def senti_word_rem(text):  #remove sentiment words function\n",
    "    arr = []\n",
    "    for i in text:\n",
    "        x = i.split()\n",
    "        filter = [k for k in x if not k in newStpWord_2] \n",
    "        filter = ' '.join(filter)\n",
    "        arr.append(filter)\n",
    "    return arr\n",
    "clean_data_without_SentiWord = senti_word_rem(clean_data)\n",
    "\n",
    "def gen_words(texts):\n",
    "    final_pos = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final_pos.append(new)\n",
    "    return (final_pos)\n",
    "\n",
    "#N-gram process def\n",
    "def to_bigram(text, count, thrs):\n",
    "    bi_list = []\n",
    "    bigram = gensim.models.Phrases(text, min_count=count, threshold=thrs) # higher threshold fewer phrases. #★★★★★★highest value★★★★★★★\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    for i in range(len(text)):\n",
    "        bi_list.append(bigram_mod[text[i]])\n",
    "    return bi_list\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_words_overall = gen_words(clean_data_without_SentiWord)\n",
    "data_words_pos = to_bigram(gen_words(senti_word_rem(pos)), 5, 100)\n",
    "data_words_neg = to_bigram(gen_words(senti_word_rem(neg)), 7, 100)\n",
    "\n",
    "\n",
    "\n",
    "#print(\"ovreall rev\")\n",
    "print(len(clean_data_without_SentiWord))\n",
    "print(\"pos rev:\")\n",
    "print(len(data_words_pos))\n",
    "print(\"neg rev:\")\n",
    "print(len(data_words_neg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95f26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = ' '.join([str(i) for i in data_words_pos])\n",
    "neg_words = ' '.join([str(i) for i in data_words_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e10038",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_pos = WordCloud().generate(pos_words)\n",
    "# 繪圖\n",
    "plt.figure()\n",
    "print(wordcloud_pos)\n",
    "print(\"Positive review WordCloud\")\n",
    "plt.imshow(wordcloud_pos, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_neg = WordCloud().generate(neg_words)\n",
    "# 繪圖\n",
    "plt.figure()\n",
    "print(\"Negative review WordCloud\")\n",
    "plt.imshow(wordcloud_neg, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"Complete_clean_dataset.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055224d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #positive review coherence\n",
    "# id2word_pos = corpora.Dictionary(data_words_pos)\n",
    "# corpus_pos = []\n",
    "# for text in data_words_pos:\n",
    "#    new = id2word_pos.doc2bow(text)\n",
    "#    corpus_pos.append(new)\n",
    "# coherence_list = []\n",
    "# for i in range(2,15):\n",
    "#    bi_lda_model_pos = gensim.models.ldamodel.LdaModel(corpus=corpus_pos,\n",
    "#                                           id2word=id2word_pos,\n",
    "#                                           num_topics=i,\n",
    "#                                           random_state=100,\n",
    "#                                           update_every=1,\n",
    "#                                           chunksize=100,\n",
    "#                                           passes=10,\n",
    "#                                           alpha=\"auto\")\n",
    "#    coherence_model_lda = CoherenceModel(model=bi_lda_model_pos, texts=data_words_pos, dictionary=id2word_pos , coherence='c_v')\n",
    "#    coherence_lda = coherence_model_lda.get_coherence()\n",
    "#    coherence_list.append(coherence_lda)\n",
    "# print(coherence_list)\n",
    "# limit=15; start=2; step=1;\n",
    "# x = range(start, limit, step)\n",
    "# plt.plot(x, coherence_list)\n",
    "# plt.xlabel(\"Num Topics\")\n",
    "# plt.ylabel(\"Positive Review Bigram Coherence score\")\n",
    "# plt.legend((\"coherence_values\"), loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604bc5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #negative review coherence\n",
    "# id2word_neg = corpora.Dictionary(data_words_neg)\n",
    "# corpus_neg = []\n",
    "# for text in data_words_neg:\n",
    "#    new = id2word_neg.doc2bow(text)\n",
    "#    corpus_neg.append(new)\n",
    "# coherence_list = []\n",
    "# for i in range(2,15):\n",
    "#    lda_model_neg = gensim.models.ldamodel.LdaModel(corpus=corpus_neg,\n",
    "#                                           id2word=id2word_neg,\n",
    "#                                           num_topics=i,\n",
    "#                                           random_state=100,\n",
    "#                                           update_every=1,\n",
    "#                                           chunksize=100,\n",
    "#                                          passes=10,\n",
    "#                                           alpha=\"auto\")\n",
    "#    coherence_model_lda = CoherenceModel(model=lda_model_neg, texts=data_words_neg, dictionary=id2word_neg , coherence='c_v')\n",
    "#    coherence_lda = coherence_model_lda.get_coherence()\n",
    "#    coherence_list.append(coherence_lda)\n",
    "# print(coherence_list)\n",
    "# limit=15; start=2; step=1;\n",
    "# x = range(start, limit, step)\n",
    "# plt.plot(x, coherence_list)\n",
    "# plt.xlabel(\"Num Topics\")\n",
    "# plt.ylabel(\"Negative Review Coherence score\")\n",
    "# plt.legend((\"coherence_values\"), loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3fbb33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275eb73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053395a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall review coherence\n",
    "#Overall topic num: 8\n",
    "#model_list, coherence_values = compute_coherence_values(dictionary=id2word_ov, corpus=corpus_ov, texts=data_words_ov, start=2, limit=15, step=1) \n",
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "#limit=15; start=2; step=1;\n",
    "#x = range(start, limit, step)\n",
    "#plt.plot(x, coherence_values)\n",
    "#plt.xlabel(\"Num Topics\")\n",
    "#plt.ylabel(\"Coherence score\")\n",
    "#plt.legend((\"coherence_values\"), loc='best')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f40a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive review coherence\n",
    "#Positive topic num: 8\n",
    "#model_list, coherence_values = compute_coherence_values(dictionary=id2word_pos, corpus=corpus_pos, texts=data_words_pos, start=2, limit=15, step=1) \n",
    "# Show graph\n",
    "#import matplotlib.pyplot as plt\n",
    "#limit=15; start=2; step=1;\n",
    "#x = range(start, limit, step)\n",
    "#plt.plot(x, coherence_values)\n",
    "#plt.xlabel(\"Num Topics\")\n",
    "#plt.ylabel(\"Coherence score\")\n",
    "#plt.legend((\"coherence_values\"), loc='best')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea226b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative review coherence\n",
    "#Negative topic num: 7\n",
    "#model_list, coherence_values = compute_coherence_values(dictionary=id2word_neg, corpus=corpus_neg, texts=data_words_neg, start=2, limit=15, step=1) \n",
    "# Show graph\n",
    "#import matplotlib.pyplot as plt\n",
    "#limit=15; start=2; step=1;\n",
    "#x = range(start, limit, step)\n",
    "#plt.plot(x, coherence_values)\n",
    "#plt.xlabel(\"Num Topics\")\n",
    "#plt.ylabel(\"Coherence score\")\n",
    "#plt.legend((\"coherence_values\"), loc='best')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f929ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89630370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c4b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #positive review coherence\n",
    "# coherence_list = []\n",
    "# for i in range(2,15):\n",
    "#    lda_model_pos = gensim.models.ldamodel.LdaModel(corpus=corpus_pos,\n",
    "#                                           id2word=id2word_pos,\n",
    "#                                           num_topics=i,\n",
    "#                                           random_state=100,\n",
    "#                                           update_every=1,\n",
    "#                                           chunksize=100,\n",
    "#                                           passes=10,\n",
    "#                                           alpha=\"auto\")\n",
    "#    coherence_model_lda = CoherenceModel(model=lda_model_pos, texts=data_words_pos, dictionary=id2word_pos , coherence='c_v')\n",
    "#    coherence_lda = coherence_model_lda.get_coherence()\n",
    "#    coherence_list.append(coherence_lda)\n",
    "# print(coherence_list)\n",
    "# limit=15; start=2; step=1;\n",
    "# x = range(start, limit, step)\n",
    "# plt.plot(x, coherence_list)\n",
    "# plt.xlabel(\"Num Topics\")\n",
    "# plt.ylabel(\"Positive Review Coherence score\")\n",
    "# plt.legend((\"coherence_values\"), loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb64dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #positive review coherence\n",
    "# coherence_list = []\n",
    "# for i in range(2,15):\n",
    "#    lda_model_pos = gensim.models.ldamodel.LdaModel(corpus=corpus_pos,\n",
    "#                                           id2word=id2word_pos,\n",
    "#                                           num_topics=i,\n",
    "#                                           random_state=100,\n",
    "#                                           update_every=1,\n",
    "#                                           chunksize=100,\n",
    "#                                           passes=10,\n",
    "#                                           alpha=\"auto\")\n",
    "#    coherence_model_lda = CoherenceModel(model=lda_model_pos, texts=data_words_pos, dictionary=id2word_pos , coherence='u_mass')\n",
    "#    coherence_lda = coherence_model_lda.get_coherence()\n",
    "#    coherence_list.append(coherence_lda)\n",
    "# print(coherence_list)\n",
    "# limit=15; start=2; step=1;\n",
    "# x = range(start, limit, step)\n",
    "# plt.plot(x, coherence_list)\n",
    "# plt.xlabel(\"Num Topics\")\n",
    "# plt.ylabel(\"Positive Review Coherence score\")\n",
    "# plt.legend((\"coherence_values\"), loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9850c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #negative review coherence\n",
    "# coherence_list = []\n",
    "# for i in range(2,15):\n",
    "#    lda_model_neg = gensim.models.ldamodel.LdaModel(corpus=corpus_neg,\n",
    "#                                           id2word=id2word_neg,\n",
    "#                                           num_topics=i,\n",
    "#                                           random_state=100,\n",
    "#                                           update_every=1,\n",
    "#                                           chunksize=100,\n",
    "#                                          passes=10,\n",
    "#                                           alpha=\"auto\")\n",
    "#    coherence_model_lda = CoherenceModel(model=lda_model_neg, texts=data_words_neg, dictionary=id2word_neg , coherence='c_v')\n",
    "#    coherence_lda = coherence_model_lda.get_coherence()\n",
    "#    coherence_list.append(coherence_lda)\n",
    "# print(coherence_list)\n",
    "# limit=15; start=2; step=1;\n",
    "# x = range(start, limit, step)\n",
    "# plt.plot(x, coherence_list)\n",
    "# plt.xlabel(\"Num Topics\")\n",
    "# plt.ylabel(\"Negative Review Coherence score\")\n",
    "# plt.legend((\"coherence_values\"), loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #negative review coherence\n",
    "# coherence_list = []\n",
    "# for i in range(2,15):\n",
    "#    lda_model_neg = gensim.models.ldamodel.LdaModel(corpus=corpus_neg,\n",
    "#                                           id2word=id2word_neg,\n",
    "#                                           num_topics=i,\n",
    "#                                           random_state=100,\n",
    "#                                           update_every=1,\n",
    "#                                           chunksize=100,\n",
    "#                                          passes=10,\n",
    "#                                           alpha=\"auto\")\n",
    "#    coherence_model_lda = CoherenceModel(model=lda_model_neg, texts=data_words_neg, dictionary=id2word_neg , coherence='u_mass')\n",
    "#    coherence_lda = coherence_model_lda.get_coherence()\n",
    "#    coherence_list.append(coherence_lda)\n",
    "# print(coherence_list)\n",
    "# limit=15; start=2; step=1;\n",
    "# x = range(start, limit, step)\n",
    "# plt.plot(x, coherence_list)\n",
    "# plt.xlabel(\"Num Topics\")\n",
    "# plt.ylabel(\"Negative Review Coherence score\")\n",
    "# plt.legend((\"coherence_values\"), loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6816d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preplexity(num_topic, corpus,dic):\n",
    "#     ladmodel = gensim.models.ldamodel.LdaModel(corpus = corpus, num_topics = num_topic, id2word = dic,random_state=100,\n",
    "#                                           update_every=1,\n",
    "#                                           chunksize=100,\n",
    "#                                          passes=10,\n",
    "#                                           alpha=\"auto\")\n",
    "#     return ladmodel.log_perplexity(corpus)\n",
    "\n",
    "# #print(preplexity(1,corpus_pos,id2word_pos))\n",
    "# limit=15; start=2; step=1;\n",
    "# x = range(start, limit, step)\n",
    "# y = []\n",
    "# for i in range(2,15):\n",
    "#     y.append(preplexity(i,corpus_pos, id2word_pos))\n",
    "# print(y)\n",
    "# plt.plot(x, y)\n",
    "# plt.xlabel(\"Num Topics\")\n",
    "# plt.ylabel(\"Positive Review Perplexity score\")\n",
    "# plt.legend((\"perplexity_values\"), loc='best')\n",
    "# plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1844baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit=15; start=2; step=1;\n",
    "# x = range(start, limit, step)\n",
    "# y = []\n",
    "# for i in range(2,15):\n",
    "#     y.append(preplexity(i,corpus_neg, id2word_neg))\n",
    "# print(y)\n",
    "# plt.plot(x, y)\n",
    "# plt.xlabel(\"Num Topics\")\n",
    "# plt.ylabel(\"Negative Review Perplexity score\")\n",
    "# plt.legend((\"perplexity_values\"), loc='best')\n",
    "# plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b19c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_ov = []\n",
    "id2word_ov=corpora.Dictionary(data_words_overall)\n",
    "for text in data_words_overall:\n",
    "    new = id2word_ov.doc2bow(text)\n",
    "    corpus_ov.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa462d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.096*\"understand\" + 0.084*\"interest\" + 0.078*\"beginner\" + 0.067*\"concept\" '\n",
      "  '+ 0.057*\"way\" + 0.052*\"helpful\" + 0.039*\"clear\" + 0.032*\"example\" + '\n",
      "  '0.024*\"practical\" + 0.021*\"simple\"'),\n",
      " (1,\n",
      "  '0.125*\"challenge\" + 0.106*\"amaze\" + 0.053*\"cover\" + 0.045*\"last\" + '\n",
      "  '0.033*\"sir\" + 0.030*\"important\" + 0.025*\"apply\" + 0.024*\"real\" + '\n",
      "  '0.024*\"finish\" + 0.021*\"difficult\"'),\n",
      " (2,\n",
      "  '0.112*\"experience\" + 0.092*\"week\" + 0.060*\"student\" + 0.049*\"exercise\" + '\n",
      "  '0.039*\"job\" + 0.032*\"specialization\" + 0.026*\"found\" + 0.025*\"every\" + '\n",
      "  '0.024*\"implement\" + 0.023*\"worth\"'),\n",
      " (3,\n",
      "  '0.120*\"fun\" + 0.103*\"teach\" + 0.065*\"new\" + 0.049*\"even\" + 0.031*\"hard\" + '\n",
      "  '0.030*\"build\" + 0.029*\"theory\" + 0.028*\"create\" + 0.026*\"fantastic\" + '\n",
      "  '0.025*\"happy\"'),\n",
      " (4,\n",
      "  '0.193*\"program\" + 0.076*\"introduction\" + 0.073*\"parallel\" + 0.060*\"start\" + '\n",
      "  '0.049*\"thing\" + 0.035*\"think\" + 0.027*\"language\" + 0.027*\"overall\" + '\n",
      "  '0.027*\"bit\" + 0.025*\"structure\"'),\n",
      " (5,\n",
      "  '0.121*\"thanks\" + 0.096*\"explain\" + 0.096*\"professor\" + 0.093*\"knowledge\" + '\n",
      "  '0.047*\"wonderful\" + 0.037*\"perfect\" + 0.035*\"task\" + 0.032*\"introductory\" + '\n",
      "  '0.030*\"world\" + 0.026*\"everything\"'),\n",
      " (6,\n",
      "  '0.133*\"assignment\" + 0.071*\"help\" + 0.058*\"material\" + 0.041*\"need\" + '\n",
      "  '0.036*\"complete\" + 0.028*\"quiz\" + 0.028*\"feel\" + 0.027*\"improve\" + '\n",
      "  '0.026*\"level\" + 0.024*\"first\"'),\n",
      " (7,\n",
      "  '0.202*\"use\" + 0.150*\"content\" + 0.060*\"though\" + 0.040*\"data\" + '\n",
      "  '0.030*\"felt\" + 0.028*\"solve\" + 0.024*\"introduce\" + 0.023*\"otherwise\" + '\n",
      "  '0.023*\"comprehensive\" + 0.022*\"available\"'),\n",
      " (8,\n",
      "  '0.106*\"useful\" + 0.094*\"lecture\" + 0.077*\"work\" + 0.069*\"code\" + '\n",
      "  '0.063*\"video\" + 0.054*\"provide\" + 0.037*\"know\" + 0.028*\"system\" + '\n",
      "  '0.021*\"still\" + 0.019*\"end\"'),\n",
      " (9,\n",
      "  '0.107*\"instructor\" + 0.077*\"explanation\" + 0.064*\"platform\" + 0.052*\"part\" '\n",
      "  '+ 0.040*\"taught\" + 0.032*\"prof\" + 0.027*\"intro\" + 0.027*\"test\" + '\n",
      "  '0.027*\"idea\" + 0.023*\"online\"'),\n",
      " (10,\n",
      "  '0.200*\"learn\" + 0.087*\"basic\" + 0.049*\"recommend\" + 0.035*\"want\" + '\n",
      "  '0.033*\"project\" + 0.033*\"topic\" + 0.032*\"class\" + 0.027*\"teacher\" + '\n",
      "  '0.022*\"iot\" + 0.020*\"information\"'),\n",
      " (11,\n",
      "  '0.192*\"enjoy\" + 0.141*\"time\" + 0.070*\"computer\" + 0.044*\"require\" + '\n",
      "  '0.038*\"easily\" + 0.029*\"engage\" + 0.027*\"yet\" + 0.026*\"general\" + '\n",
      "  '0.023*\"foundation\" + 0.023*\"allow\"')]\n",
      "\n",
      "Positive Review Perplexity:  -8.295147272605798\n",
      "[(0,\n",
      "  '0.096*\"difficult\" + 0.073*\"program\" + 0.060*\"learn\" + 0.043*\"bit\" + '\n",
      "  '0.034*\"think\" + 0.028*\"student\" + 0.025*\"part\" + 0.025*\"fail\" + '\n",
      "  '0.023*\"answer\" + 0.023*\"class\"'),\n",
      " (1,\n",
      "  '0.294*\"problem\" + 0.067*\"wrong\" + 0.058*\"solve\" + 0.039*\"know\" + '\n",
      "  '0.032*\"though\" + 0.028*\"idea\" + 0.023*\"ask\" + 0.022*\"cant\" + 0.020*\"submit\" '\n",
      "  '+ 0.019*\"real\"'),\n",
      " (2,\n",
      "  '0.174*\"time\" + 0.079*\"first\" + 0.064*\"work\" + 0.049*\"content\" + '\n",
      "  '0.048*\"material\" + 0.042*\"waste\" + 0.041*\"without\" + 0.036*\"rather\" + '\n",
      "  '0.035*\"cover\" + 0.025*\"boring\"'),\n",
      " (3,\n",
      "  '0.084*\"never\" + 0.066*\"teacher\" + 0.056*\"although\" + 0.046*\"always\" + '\n",
      "  '0.045*\"possible\" + 0.045*\"overall\" + 0.031*\"forget\" + 0.031*\"update\" + '\n",
      "  '0.031*\"all\" + 0.029*\"disappoint\"'),\n",
      " (4,\n",
      "  '0.116*\"enough\" + 0.084*\"practice\" + 0.059*\"correct\" + 0.058*\"taught\" + '\n",
      "  '0.047*\"structure\" + 0.046*\"expect\" + 0.040*\"feedback\" + 0.031*\"learnt\" + '\n",
      "  '0.025*\"incorrect\" + 0.023*\"rigorous\"'),\n",
      " (5,\n",
      "  '0.120*\"assignment\" + 0.057*\"hard\" + 0.030*\"complete\" + 0.027*\"sleuth\" + '\n",
      "  '0.027*\"frustrate\" + 0.026*\"need\" + 0.022*\"exercise\" + 0.022*\"confuse\" + '\n",
      "  '0.020*\"thing\" + 0.018*\"last\"'),\n",
      " (6,\n",
      "  '0.123*\"code\" + 0.085*\"test\" + 0.045*\"found\" + 0.044*\"miss\" + 0.042*\"still\" '\n",
      "  '+ 0.033*\"struggle\" + 0.021*\"data\" + 0.021*\"hour\" + 0.019*\"autograder\" + '\n",
      "  '0.019*\"practical\"'),\n",
      " (7,\n",
      "  '0.134*\"concept\" + 0.098*\"basic\" + 0.070*\"since\" + 0.065*\"lesson\" + '\n",
      "  '0.044*\"extremely\" + 0.042*\"come\" + 0.032*\"high\" + 0.023*\"step\" + '\n",
      "  '0.021*\"must\" + 0.021*\"next\"'),\n",
      " (8,\n",
      "  '0.119*\"video\" + 0.094*\"quiz\" + 0.074*\"question\" + 0.053*\"provide\" + '\n",
      "  '0.047*\"feel\" + 0.030*\"recommend\" + 0.024*\"pay\" + 0.024*\"simple\" + '\n",
      "  '0.023*\"completely\" + 0.022*\"already\"'),\n",
      " (9,\n",
      "  '0.104*\"understand\" + 0.066*\"use\" + 0.061*\"lecture\" + 0.050*\"difficulty\" + '\n",
      "  '0.050*\"way\" + 0.046*\"case\" + 0.030*\"poor\" + 0.030*\"due\" + '\n",
      "  '0.024*\"discussion_forum\" + 0.022*\"different\"'),\n",
      " (10,\n",
      "  '0.076*\"error\" + 0.057*\"find\" + 0.046*\"new\" + 0.043*\"forum\" + 0.041*\"low\" + '\n",
      "  '0.040*\"pas\" + 0.038*\"want\" + 0.035*\"challenge\" + 0.034*\"figure\" + '\n",
      "  '0.033*\"may\"'),\n",
      " (11,\n",
      "  '0.091*\"explanation\" + 0.059*\"point\" + 0.045*\"everything\" + 0.043*\"short\" + '\n",
      "  '0.040*\"actually\" + 0.035*\"somewhat\" + 0.032*\"reading\" + 0.027*\"vague\" + '\n",
      "  '0.023*\"de\" + 0.019*\"subject\"'),\n",
      " (12,\n",
      "  '0.141*\"week\" + 0.042*\"lack\" + 0.041*\"beginner\" + 0.038*\"explain\" + '\n",
      "  '0.035*\"sometimes\" + 0.034*\"tough\" + 0.033*\"topic\" + 0.026*\"example\" + '\n",
      "  '0.025*\"task\" + 0.024*\"algorithm\"')]\n",
      "\n",
      "Negative Review Perplexity:  -9.393868518153708\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#cm = CoherenceModel(model=lda_model_ov, corpus=corpus_ov, coherence='u_mass')\n",
    "#coherence = cm.get_coherence()\n",
    "#print('\\nOverall Review Cohernece: ',coherence)\n",
    "\n",
    "#if __name__=='__main__':\n",
    "#    coherence_model_lda = CoherenceModel(model=lda_model_ov, texts=clean_data_without_SentiWord, dictionary=id2word_ov, coherence='c_v')\n",
    "#    coherence_lda = coherence_model_lda.get_coherence()\n",
    "#    print('\\nCoherence Score: ', coherence_lda)\n",
    "#--------------------------positive lda analysis--------------------------\n",
    "id2word_pos = corpora.Dictionary(data_words_pos)\n",
    "corpus_pos = []\n",
    "for text in data_words_pos:\n",
    "    new = id2word_pos.doc2bow(text)\n",
    "    corpus_pos.append(new)\n",
    "lda_model_pos = gensim.models.ldamodel.LdaModel(corpus=corpus_pos,\n",
    "                                           id2word=id2word_pos,\n",
    "                                           num_topics=12,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=\"auto\")\n",
    "pprint(lda_model_pos.print_topics(12))     \n",
    "p_doc_term_matrix_pos = [id2word_pos.doc2bow(doc) for doc in data_words_pos]\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPositive Review Perplexity: ', lda_model_pos.log_perplexity(p_doc_term_matrix_pos))   #Positive Review Perplexity:  -7.7604093115426585\n",
    "# a measure of how good the model is. lower the better.\n",
    "\n",
    "\n",
    "#--------------------------negative lda analysis--------------------------\n",
    "id2word_neg = corpora.Dictionary(data_words_neg)\n",
    "corpus_neg = []\n",
    "for text in data_words_neg:\n",
    "    new = id2word_neg.doc2bow(text)\n",
    "    corpus_neg.append(new)\n",
    "lda_model_neg = gensim.models.ldamodel.LdaModel(corpus=corpus_neg,\n",
    "                                           id2word=id2word_neg,\n",
    "                                           num_topics=13,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=\"auto\")\n",
    "pprint(lda_model_neg.print_topics(13))   \n",
    "p_doc_term_matrix_neg = [id2word_neg.doc2bow(doc) for doc in data_words_neg]\n",
    "# Compute Perplexity\n",
    "print('\\nNegative Review Perplexity: ', lda_model_neg.log_perplexity(p_doc_term_matrix_neg))   #Negative Review Perplexity:  -9.519325542067824\n",
    "# a measure of how good the model is. lower the better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d813be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud = WordCloud().generate(data_words_pos)\n",
    "\n",
    "# # 繪圖\n",
    "# plt.figure()\n",
    "# plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive Vis\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model_pos, corpus_pos, id2word_pos, mds=\"tsne\")\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c2af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative Vis\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model_neg, corpus_neg, id2word_neg, mds=\"tsne\")\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5494ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #N-gram process Positive\n",
    "# # Build the positive bigram and trigram models\n",
    "# bigram = gensim.models.Phrases(data_words_pos, min_count=5, threshold=100) # higher threshold fewer phrases. #★★★★★★highest value★★★★★★★\n",
    "# trigram = gensim.models.Phrases(bigram[data_words_pos], threshold=100)  \n",
    "\n",
    "# # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "# bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "# trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# bi_data_words_pos = []\n",
    "# # See trigram example\n",
    "# for i in range(len(data_words_pos)):\n",
    "#     bi_data_words_pos.append(bigram_mod[data_words_pos[i]])\n",
    "# print(bi_data_words_pos)\n",
    "# #print(trigram_mod[bigram_mod[data_words_pos[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0d9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5f998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #N-gram process Negative\n",
    "# # Build the positive bigram and trigram models\n",
    "# bigram = gensim.models.Phrases(data_words_neg, min_count=7, threshold=100) # higher threshold fewer phrases. #★★★★★★highest value★★★★★★★\n",
    "# trigram = gensim.models.Phrases(bigram[data_words_neg], threshold=100)  \n",
    "\n",
    "# # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "# bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "# trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# bi_data_words_neg = []\n",
    "# # See trigram example\n",
    "# for i in range(len(data_words_neg)):\n",
    "#     bi_data_words_neg.append(bigram_mod[data_words_neg[i]])\n",
    "# print(bi_data_words_neg)\n",
    "# #print(trigram_mod[bigram_mod[data_words_pos[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb19ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca93c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
